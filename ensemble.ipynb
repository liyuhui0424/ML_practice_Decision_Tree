{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/sales.csv')\n",
    "df.dropna(subset=['price'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cost</th>\n",
       "      <th>price</th>\n",
       "      <th>weight</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>product_type</th>\n",
       "      <th>product_level</th>\n",
       "      <th>maker</th>\n",
       "      <th>ingredient</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$333k</td>\n",
       "      <td>$300,492</td>\n",
       "      <td>3 Ton 90 Kg</td>\n",
       "      <td>Dec 19 2008</td>\n",
       "      <td>Q,B</td>\n",
       "      <td>advanced</td>\n",
       "      <td>M14122</td>\n",
       "      <td>IN732052,IN732053</td>\n",
       "      <td>2.76 meters</td>\n",
       "      <td>97 cm</td>\n",
       "      <td>26 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>$430,570</td>\n",
       "      <td>3 Ton 30 Kg</td>\n",
       "      <td>Sep 10 1997</td>\n",
       "      <td>J,D</td>\n",
       "      <td>basic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN732054,IN732055,IN732056,IN732057,IN732058</td>\n",
       "      <td>2.67 meters</td>\n",
       "      <td>98 cm</td>\n",
       "      <td>26 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$270k</td>\n",
       "      <td>$213,070</td>\n",
       "      <td>3 Ton 40 Kg</td>\n",
       "      <td>Sep 05 2001</td>\n",
       "      <td>J,D</td>\n",
       "      <td>basic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN732054,IN732059,IN732060</td>\n",
       "      <td>3.0 meters</td>\n",
       "      <td>93 cm</td>\n",
       "      <td>24 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>$229,174</td>\n",
       "      <td>3 Ton 50 Kg</td>\n",
       "      <td>Dec 23 2016</td>\n",
       "      <td>U</td>\n",
       "      <td>advanced</td>\n",
       "      <td>M14123</td>\n",
       "      <td>IN732061,IN732062,IN732063</td>\n",
       "      <td>2.5 meters</td>\n",
       "      <td>102 cm</td>\n",
       "      <td>27 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$97k</td>\n",
       "      <td>$122,659</td>\n",
       "      <td>2 Ton 970 Kg</td>\n",
       "      <td>Jan 12 2000</td>\n",
       "      <td>D,R</td>\n",
       "      <td>advanced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN732064,IN732065,IN732066</td>\n",
       "      <td>2.47 meters</td>\n",
       "      <td>101 cm</td>\n",
       "      <td>26 cm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cost     price        weight purchase_date product_type product_level  \\\n",
       "0  $333k  $300,492   3 Ton 90 Kg   Dec 19 2008          Q,B      advanced   \n",
       "1    NaN  $430,570   3 Ton 30 Kg   Sep 10 1997          J,D         basic   \n",
       "2  $270k  $213,070   3 Ton 40 Kg   Sep 05 2001          J,D         basic   \n",
       "3    NaN  $229,174   3 Ton 50 Kg   Dec 23 2016            U      advanced   \n",
       "4   $97k  $122,659  2 Ton 970 Kg   Jan 12 2000          D,R      advanced   \n",
       "\n",
       "    maker                                    ingredient       height   width  \\\n",
       "0  M14122                             IN732052,IN732053  2.76 meters   97 cm   \n",
       "1     NaN  IN732054,IN732055,IN732056,IN732057,IN732058  2.67 meters   98 cm   \n",
       "2     NaN                    IN732054,IN732059,IN732060   3.0 meters   93 cm   \n",
       "3  M14123                    IN732061,IN732062,IN732063   2.5 meters  102 cm   \n",
       "4     NaN                    IN732064,IN732065,IN732066  2.47 meters  101 cm   \n",
       "\n",
       "   depth  \n",
       "0  26 cm  \n",
       "1  26 cm  \n",
       "2  24 cm  \n",
       "3  27 cm  \n",
       "4  26 cm  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = pd.to_datetime(df.purchase_date).dt.year\n",
    "train_raw = df[df.year < 2015].reset_index(drop=True)\n",
    "test_raw = df[df.year >= 2015].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Build a pipeline with **RandomForestRegressor** to predict **price** with **cost**, **weight**, **height**, **width**, **depth**, and **volumn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_raw['price'].map(lambda x: x if type(x) == float else float(x.strip('$').replace(',', '')))\n",
    "y_test = test_raw['price'].map(lambda x: x if type(x) == float else float(x.strip('$').replace(',', '')))\n",
    "\n",
    "def weight2num(x):\n",
    "    \"\"\"\n",
    "    This function transform weight string to numerical value.\n",
    "    \"\"\"\n",
    "    if type(x) == str: \n",
    "        y = x.split(\" Ton \")    \n",
    "        return float(y[0]) * 1000 + float(y[1].replace(' Kg',''))\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "class Numerical_Transformer(object):\n",
    "    def fit(self, X, y=None):\n",
    "        self.mean = {}\n",
    "        df = pd.DataFrame()        \n",
    "        df['cost'] = X['cost'].map(lambda x: x if type(x) == float else float(x.strip('$').strip('k'))*1000)\n",
    "        self.mean['cost'] = df['cost'].mean()\n",
    "        df['weight'] = X['weight'].map(weight2num)\n",
    "        self.mean['weight'] = df['weight'].mean()\n",
    "        df['height'] = X['height'].map(lambda x: x if type(x) == float else float(x.replace('meters', '')))\n",
    "        self.mean['height'] = df['height'].mean()\n",
    "        df['width'] = X['width'].map(lambda x: x if type(x) == float else float(x.replace('cm', '')))\n",
    "        self.mean['width'] = df['width'].mean()\n",
    "        df['depth'] = X['depth'].map(lambda x: x if type(x) == float else float(x.replace('cm', '')))\n",
    "        self.mean['depth'] = df['depth'].mean()\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        df = pd.DataFrame()\n",
    "        df['cost'] = X['cost'].map(lambda x: x if type(x) == float else float(x.strip('$').strip('k'))*1000)\n",
    "        df['weight'] = X['weight'].map(weight2num)\n",
    "        df['height'] = X['height'].map(lambda x: x if type(x) == float else float(x.replace('meters', '')))\n",
    "        df['width'] = X['width'].map(lambda x: x if type(x) == float else float(x.replace('cm', '')))\n",
    "        df['depth'] = X['depth'].map(lambda x: x if type(x) == float else float(x.replace('cm', '')))\n",
    "        return df.fillna(self.mean)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ntf',\n",
       "                 <__main__.Numerical_Transformer object at 0x000001FC94A90BE0>),\n",
       "                ('norm', StandardScaler()),\n",
       "                ('rfr',\n",
       "                 RandomForestRegressor(max_depth=3, min_samples_split=5))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "steps = [('ntf', Numerical_Transformer()),\n",
    "         ('norm', StandardScaler()),\n",
    "         ('rfr', RandomForestRegressor(max_depth=3, min_samples_split=5))]\n",
    "\n",
    "model = Pipeline(steps)\n",
    "\n",
    "model.fit(train_raw, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Calculate the train/test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MAE: 1.04e+05\n",
      "train MSE: 2.51e+10\n",
      "train R2: 0.411\n",
      "train MAE: 1.30e+05\n",
      "train MSE: 5.42e+10\n",
      "train R2: 0.371\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_raw, y_train)\n",
    "y_train_pred = model.predict(train_raw)\n",
    "print('train MAE: {0:.2e}'.format(mean_absolute_error(y_train, y_train_pred)))\n",
    "print('train MSE: {0:.2e}'.format(mean_squared_error(y_train, y_train_pred)))\n",
    "print('train R2: {0:.3f}'.format(r2_score(y_train, y_train_pred)))\n",
    "\n",
    "y_test_pred = model.predict(test_raw)\n",
    "print('train MAE: {0:.2e}'.format(mean_absolute_error(y_test, y_test_pred)))\n",
    "print('train MSE: {0:.2e}'.format(mean_squared_error(y_test, y_test_pred)))\n",
    "print('train R2: {0:.3f}'.format(r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Plot the feature importance in a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.bar(['cost','weight','height','width','depth'], model[2].feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> How does Random Forest work? Why is it better than a single decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest is a way of averaging multiple decision trees. Forests give the effects of k-fold cross-validation. Thus it \n",
    "# efficiently prevents overfitting that usually happens when using a single decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> Why is Random Forest better than a single decision tree? How does it decrease model error? How does it affect bias and virance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forests take the teamwork of many trees thus improving the performance of a single random tree. The technique use \n",
    "# bagging (bootstrap aggregating) on the training data set to train multiple decision trees, and use the avearge of all the \n",
    "# tree's prediction ot predict the result. Bagging de-correlates the trees by training them with different data set, so while\n",
    "# the performance of a single tree is sensitive to the noise of the training data set, the average of all trees is not, thus \n",
    "# Random Forest decreases model error. It reduces virance while not affect bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> What is Bagging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging, or bootstrap aggregating is a data resampling method. It resamples the data with many times, each time resamples the \n",
    "# same size of data points from the original data set but with replacement (so some data points may be sampled multiple times, \n",
    "# while some data point may not be sampled). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Tune hyperparameters with k-fold cross validation to optimize model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "import numpy as np\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=2023)\n",
    "\n",
    "scorer_method = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "steps = [('ntf', Numerical_Transformer()),\n",
    "         ('norm', StandardScaler()),\n",
    "         ('rfr', RandomForestRegressor())]\n",
    "\n",
    "model = Pipeline(steps)\n",
    "\n",
    "model = Pipeline(steps)\n",
    "\n",
    "n_estimators = [5, 10, 20, 50, 100, 200]\n",
    "max_depths = range(1, 10)\n",
    "min_samples_splits = range(2, 5)\n",
    "\n",
    "\n",
    "grid = dict()\n",
    "#grid['lr__alpha'] = lasso_alphas \n",
    "grid['rfr__n_estimators'] = n_estimators\n",
    "grid['rfr__max_depth'] = max_depths\n",
    "grid['rfr__min_samples_split'] = min_samples_splits \n",
    "\n",
    "\n",
    "search = GridSearchCV(model, param_grid = grid, scoring = scorer_method, \\\n",
    "                      cv = kf, n_jobs = -1, error_score = np.NaN).fit(train_raw, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -27081263671.25480\n",
      "Config: {'rfr__max_depth': 3, 'rfr__min_samples_split': 2, 'rfr__n_estimators': 5}\n"
     ]
    }
   ],
   "source": [
    "print('MAE: %.5f' % search.best_score_)\n",
    "print('Config: %s' % search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MAE: 1.05e+05\n",
      "train MSE: 2.48e+10\n",
      "train R2: 0.419\n",
      "train MAE: 1.31e+05\n",
      "train MSE: 5.45e+10\n",
      "train R2: 0.367\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = search.predict(train_raw)\n",
    "print('train MAE: {0:.2e}'.format(mean_absolute_error(y_train, y_train_pred)))\n",
    "print('train MSE: {0:.2e}'.format(mean_squared_error(y_train, y_train_pred)))\n",
    "print('train R2: {0:.3f}'.format(r2_score(y_train, y_train_pred)))\n",
    "\n",
    "y_test_pred = search.predict(test_raw)\n",
    "print('train MAE: {0:.2e}'.format(mean_absolute_error(y_test, y_test_pred)))\n",
    "print('train MSE: {0:.2e}'.format(mean_squared_error(y_test, y_test_pred)))\n",
    "print('train R2: {0:.3f}'.format(r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MAE: 4.29e+04\n",
      "train MSE: 4.31e+09\n",
      "train R2: 0.899\n",
      "train MAE: 1.29e+05\n",
      "train MSE: 5.35e+10\n",
      "train R2: 0.379\n"
     ]
    }
   ],
   "source": [
    "steps = [('ntf', Numerical_Transformer()),\n",
    "         ('norm', StandardScaler()),\n",
    "         ('rfr', RandomForestRegressor(n_estimators=1000))]\n",
    "\n",
    "model1 = Pipeline(steps)\n",
    "\n",
    "model1.fit(train_raw, y_train)\n",
    "y_train_pred = model1.predict(train_raw)\n",
    "print('train MAE: {0:.2e}'.format(mean_absolute_error(y_train, y_train_pred)))\n",
    "print('train MSE: {0:.2e}'.format(mean_squared_error(y_train, y_train_pred)))\n",
    "print('train R2: {0:.3f}'.format(r2_score(y_train, y_train_pred)))\n",
    "\n",
    "y_test_pred = model1.predict(test_raw)\n",
    "print('train MAE: {0:.2e}'.format(mean_absolute_error(y_test, y_test_pred)))\n",
    "print('train MSE: {0:.2e}'.format(mean_squared_error(y_test, y_test_pred)))\n",
    "print('train R2: {0:.3f}'.format(r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> What are the hyper parameters which can effetively affect model performance? How do they affect the performance respectively?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators should be set big enough to reduce the variance. Surprisingly, when n_estimators is big enough, setting the other\n",
    "# hyper parameters will increases variance in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Build a pipeline with **GradientBoostingRegressor** to predict **price** with **cost**, **weight**, **height**, **width**, **depth**, and **volumn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ntf',\n",
       "                 <__main__.Numerical_Transformer object at 0x000001FCA3A29E50>),\n",
       "                ('norm', StandardScaler()),\n",
       "                ('gbr',\n",
       "                 GradientBoostingRegressor(learning_rate=0.01,\n",
       "                                           n_estimators=1000))])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "steps = [('ntf', Numerical_Transformer()),\n",
    "         ('norm', StandardScaler()),\n",
    "         ('gbr', GradientBoostingRegressor(n_estimators=1000, learning_rate=0.01))]\n",
    "\n",
    "model = Pipeline(steps)\n",
    "\n",
    "model.fit(train_raw, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Calculate the train/test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MAE: 9.50e+04\n",
      "train MSE: 2.01e+10\n",
      "train R2: 0.528\n",
      "train MAE: 1.26e+05\n",
      "train MSE: 5.31e+10\n",
      "train R2: 0.384\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_raw, y_train)\n",
    "y_train_pred = model.predict(train_raw)\n",
    "print('train MAE: {0:.2e}'.format(mean_absolute_error(y_train, y_train_pred)))\n",
    "print('train MSE: {0:.2e}'.format(mean_squared_error(y_train, y_train_pred)))\n",
    "print('train R2: {0:.3f}'.format(r2_score(y_train, y_train_pred)))\n",
    "\n",
    "y_test_pred = model.predict(test_raw)\n",
    "print('train MAE: {0:.2e}'.format(mean_absolute_error(y_test, y_test_pred)))\n",
    "print('train MSE: {0:.2e}'.format(mean_squared_error(y_test, y_test_pred)))\n",
    "print('train R2: {0:.3f}'.format(r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Plot the feature importance in a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(['cost','weight','height','width','depth'], model[2].feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> How does gradient boosting tree work? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosting tree weak learners into a strong learner in an iterative fashion.The algorithm repeatly improve the model\n",
    "# by fitting the risiduals between the previous model prediction and the actual observation value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> What is boosting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting is a method in machine learning to reduce errors in preditive data analysis. Boosting tries to overcome predicting \n",
    "# errors by training multiple models sequentially to improve accuracy of the overall system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> Compare gradient boosting trees and random forest. What are the pros and cons of these two models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest combines multiple single trees to work simultaneously while gradient boosting trees train the decision trees \n",
    "# sequentially. \n",
    "# Gradient boosting trees outperform random forest if the hyper parameters are well-tuned. However, it is more difficult to \n",
    "# the parameters in Gradient boosting trees. The gradient boosting trees also tend to over-fit when the data is noisy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Tune hyperparameters with k-fold cross validation to optimize model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=2023)\n",
    "\n",
    "scorer_method = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "steps = [('ntf', Numerical_Transformer()),\n",
    "         ('norm', StandardScaler()),\n",
    "         ('gbr', GradientBoostingRegressor())]\n",
    "\n",
    "model = Pipeline(steps)\n",
    "\n",
    "model = Pipeline(steps)\n",
    "\n",
    "n_estimators = [5, 10, 20, 50, 100, 200, 500, 1000]\n",
    "learning_rate = [0.001, 0.01, 0.1, 1]\n",
    "min_samples_splits = range(2, 10)\n",
    "\n",
    "grid = dict()\n",
    "#grid['lr__alpha'] = lasso_alphas \n",
    "grid['gbr__n_estimators'] = n_estimators\n",
    "grid['gbr__learning_rate'] = learning_rate\n",
    "grid['gbr__min_samples_split'] = min_samples_splits\n",
    "\n",
    "search = GridSearchCV(model, param_grid = grid, scoring = scorer_method, \\\n",
    "                      cv = kf, n_jobs = -1, error_score = np.NaN).fit(train_raw, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -27562138030.26377\n",
      "Config: {'gbr__learning_rate': 0.1, 'gbr__min_samples_split': 6, 'gbr__n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "print('MAE: %.5f' % search.best_score_)\n",
    "print('Config: %s' % search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MAE: 9.83e+04\n",
      "train MSE: 2.19e+10\n",
      "train R2: 0.486\n",
      "train MAE: 1.26e+05\n",
      "train MSE: 5.31e+10\n",
      "train R2: 0.384\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = search.predict(train_raw)\n",
    "print('train MAE: {0:.2e}'.format(mean_absolute_error(y_train, y_train_pred)))\n",
    "print('train MSE: {0:.2e}'.format(mean_squared_error(y_train, y_train_pred)))\n",
    "print('train R2: {0:.3f}'.format(r2_score(y_train, y_train_pred)))\n",
    "\n",
    "y_test_pred = search.predict(test_raw)\n",
    "print('train MAE: {0:.2e}'.format(mean_absolute_error(y_test, y_test_pred)))\n",
    "print('train MSE: {0:.2e}'.format(mean_squared_error(y_test, y_test_pred)))\n",
    "print('train R2: {0:.3f}'.format(r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> What are the hyper parameters which can effetively affect model performance? How do they affect the performance respectively?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate and n_estimator can affect model performance. Learning rate control how fast the outcome from each tree will \n",
    "# be scaled. n_estimator controls the number of the trees. If the learning rate is small, it takes more n_estimator to train\n",
    "# the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Build a pipeline with **XGBRegressor** to predict **price** with **cost**, **weight**, **height**, **width**, **depth**, and **volumn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.11.0\n",
      "  latest version: 22.11.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=22.11.1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\liyuh\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - xgboost\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _py-xgboost-mutex-2.0      |            cpu_0          11 KB  conda-forge\n",
      "    conda-22.11.1              |   py39hcbf5309_1         908 KB  conda-forge\n",
      "    libxgboost-1.5.0           |       hd77b12b_2         1.3 MB\n",
      "    py-xgboost-1.5.0           |   py39haa95532_2         156 KB\n",
      "    python_abi-3.9             |           2_cp39           4 KB  conda-forge\n",
      "    xgboost-1.5.0              |   py39haa95532_2          15 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         2.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _py-xgboost-mutex  conda-forge/win-64::_py-xgboost-mutex-2.0-cpu_0 \n",
      "  libxgboost         pkgs/main/win-64::libxgboost-1.5.0-hd77b12b_2 \n",
      "  py-xgboost         pkgs/main/win-64::py-xgboost-1.5.0-py39haa95532_2 \n",
      "  python_abi         conda-forge/win-64::python_abi-3.9-2_cp39 \n",
      "  xgboost            pkgs/main/win-64::xgboost-1.5.0-py39haa95532_2 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda              pkgs/main::conda-22.11.0-py39haa95532~ --> conda-forge::conda-22.11.1-py39hcbf5309_1 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "python_abi-3.9       | 4 KB      |            |   0% \n",
      "\n",
      "py-xgboost-1.5.0     | 156 KB    |            |   0% \u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    |            |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xgboost-1.5.0        | 15 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_py-xgboost-mutex-2. | 11 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "python_abi-3.9       | 4 KB      | ########## | 100% \n",
      "python_abi-3.9       | 4 KB      | ########## | 100% \n",
      "\n",
      "py-xgboost-1.5.0     | 156 KB    | #          |  10% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_py-xgboost-mutex-2. | 11 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_py-xgboost-mutex-2. | 11 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | 1          |   1% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | 1          |   2% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | 3          |   4% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | 2          |   2% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "py-xgboost-1.5.0     | 156 KB    | ##         |  20% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | 3          |   4% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | 5          |   5% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | 8          |   8% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "py-xgboost-1.5.0     | 156 KB    | ####       |  41% \u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | 7          |   7% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | #          |  11% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | 9          |   9% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "py-xgboost-1.5.0     | 156 KB    | #####1     |  51% \u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | #4         |  14% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | #1         |  12% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "py-xgboost-1.5.0     | 156 KB    | ########1  |  82% \u001b[A\n",
      "\n",
      "py-xgboost-1.5.0     | 156 KB    | #########2 |  92% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | #2         |  13% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "py-xgboost-1.5.0     | 156 KB    | ########## | 100% \u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | ##1        |  21% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | #4         |  14% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "py-xgboost-1.5.0     | 156 KB    | ########## | 100% \u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | ##2        |  23% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | #5         |  15% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | ##6        |  26% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | ##9        |  30% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | #6         |  16% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | ###3       |  33% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | #8         |  19% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | ###7       |  37% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | #9         |  20% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | ####       |  41% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xgboost-1.5.0        | 15 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | ####2      |  42% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xgboost-1.5.0        | 15 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ##2        |  22% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | ####4      |  44% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ##4        |  25% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | ####9      |  49% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ##5        |  26% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | #####2     |  53% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ##6        |  27% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ##8        |  28% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | #####6     |  56% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ##9        |  29% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | #####9     |  60% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ###        |  30% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | ######3    |  63% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | ######8    |  69% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ###1       |  32% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | #######2   |  72% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | #######5   |  76% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ###5       |  35% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ###6       |  36% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | #######9   |  79% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | ########2  |  83% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | ########6  |  86% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ###8       |  39% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | #########1 |  92% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ####       |  41% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | #########5 |  95% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ####3      |  43% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ####4      |  44% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-22.11.1        | 908 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ####8      |  48% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | #####      |  50% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | #####1     |  52% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | #####2     |  53% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | #####3     |  54% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | #####5     |  55% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | #####6     |  56% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | #####7     |  57% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | #####8     |  59% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ######     |  61% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ######3    |  63% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ######4    |  64% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ######5    |  66% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ######6    |  67% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ######7    |  68% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ######9    |  69% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | #######2   |  73% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | #######4   |  75% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | #######7   |  77% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | #######9   |  80% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ########1  |  82% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ########4  |  84% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ########6  |  87% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ########8  |  89% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | #########1 |  91% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | #########3 |  94% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | #########6 |  96% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-1.5.0     | 1.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "                                                     \n",
      "\n",
      "\n",
      "                                                     \u001b[A\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ntf',\n",
       "                 <__main__.Numerical_Transformer object at 0x000001FCDB1537C0>),\n",
       "                ('norm', StandardScaler()),\n",
       "                ('xgb',\n",
       "                 XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                              colsample_bylevel=1, colsample_bynode=1,\n",
       "                              colsample_bytree=1, enable_categorical=False,\n",
       "                              gamma=0, gpu_id=-1, importance_type=None,\n",
       "                              interaction_constraints='', learning_rate=1,\n",
       "                              max_delta_step=0, max_depth=2, min_child_weight=1,\n",
       "                              missing=nan, monotone_constraints='()',\n",
       "                              n_estimators=2, n_jobs=16, num_parallel_tree=1,\n",
       "                              predictor='auto', random_state=0, reg_alpha=0,\n",
       "                              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "                              tree_method='exact', validate_parameters=1,\n",
       "                              verbosity=None))])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "steps = [('ntf', Numerical_Transformer()),\n",
    "         ('norm', StandardScaler()),\n",
    "         ('xgb', XGBRegressor(n_estimators=2, max_depth=2, learning_rate=1))]\n",
    "\n",
    "model = Pipeline(steps)\n",
    "\n",
    "model.fit(train_raw, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Calculate the train/test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MAE: 1.05e+05\n",
      "train MSE: 2.65e+10\n",
      "train R2: 0.378\n",
      "train MAE: 1.31e+05\n",
      "train MSE: 5.71e+10\n",
      "train R2: 0.337\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_raw, y_train)\n",
    "y_train_pred = model.predict(train_raw)\n",
    "print('train MAE: {0:.2e}'.format(mean_absolute_error(y_train, y_train_pred)))\n",
    "print('train MSE: {0:.2e}'.format(mean_squared_error(y_train, y_train_pred)))\n",
    "print('train R2: {0:.3f}'.format(r2_score(y_train, y_train_pred)))\n",
    "\n",
    "y_test_pred = model.predict(test_raw)\n",
    "print('train MAE: {0:.2e}'.format(mean_absolute_error(y_test, y_test_pred)))\n",
    "print('train MSE: {0:.2e}'.format(mean_squared_error(y_test, y_test_pred)))\n",
    "print('train R2: {0:.3f}'.format(r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Plot the feature importance in a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(['cost','weight','height','width','depth'], model[2].feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Tune hyperparameters with k-fold cross validation to optimize model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://xgboost.readthedocs.io/en/stable/tutorials/param_tuning.html\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=2023)\n",
    "\n",
    "scorer_method = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "steps = [('ntf', Numerical_Transformer()),\n",
    "         ('norm', StandardScaler()),\n",
    "         ('xgb', XGBRegressor())]\n",
    "\n",
    "\n",
    "model = Pipeline(steps)\n",
    "\n",
    "gamma = [x*0.1 for x in range(10)]\n",
    "max_depth = range(1, 8)\n",
    "min_child_weight = [0.1, 0.2, 0.5, 1.0, 2.0, 5.0, 10]\n",
    "subsample = [0.3, 0.5, 0.7]\n",
    "\n",
    "grid = dict()\n",
    "#grid['lr__alpha'] = lasso_alphas \n",
    "grid['xgb__gamma'] = gamma\n",
    "grid['xgb__max_depth'] = max_depth\n",
    "grid['xgb__min_child_weight'] = min_child_weight\n",
    "grid['xgb__subsample'] = subsample\n",
    "\n",
    "search = GridSearchCV(model, param_grid = grid, scoring = scorer_method, \\\n",
    "                      cv = kf, n_jobs = -1, error_score = np.NaN).fit(train_raw, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -27615090233.68605\n",
      "Config: {'xgb__gamma': 0.0, 'xgb__max_depth': 1, 'xgb__min_child_weight': 2.0, 'xgb__subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print('MAE: %.5f' % search.best_score_)\n",
    "print('Config: %s' % search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MAE: 1.03e+05\n",
      "train MSE: 2.47e+10\n",
      "train R2: 0.420\n",
      "train MAE: 1.26e+05\n",
      "train MSE: 5.10e+10\n",
      "train R2: 0.408\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = search.predict(train_raw)\n",
    "print('train MAE: {0:.2e}'.format(mean_absolute_error(y_train, y_train_pred)))\n",
    "print('train MSE: {0:.2e}'.format(mean_squared_error(y_train, y_train_pred)))\n",
    "print('train R2: {0:.3f}'.format(r2_score(y_train, y_train_pred)))\n",
    "\n",
    "y_test_pred = search.predict(test_raw)\n",
    "print('train MAE: {0:.2e}'.format(mean_absolute_error(y_test, y_test_pred)))\n",
    "print('train MSE: {0:.2e}'.format(mean_squared_error(y_test, y_test_pred)))\n",
    "print('train R2: {0:.3f}'.format(r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> What are the hyper parameters which can effetively affect model performance? How do they affect the performance respectively?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamma, max_depth, min_child_weight and subsample are important parameters affect model performance. The first three parameters\n",
    "# control the complexity of the model, while the subsample add randomness in the training to make it robust to noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> What is the relationship and difference between Xgboost and gradient boosting trees? Why Xgboost performs better than graident boosting trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xgboost is an implement of gradient boosting trees algorithm. Xgboost minimizes a regularized (L1 or L2) objective function. \n",
    "# So Xgboost outperforms gradient boosting trees in handling overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
